{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to the Ivory Tower Blog","text":"<p>I'm Anders Sundman, and this blog is a collection of my musings on programming, software engineering, and craftsmanship. I write about how we developers conjure things into existence from technical, social, and philosophical perspectives.</p> <p>After writing code for 30+ years, I'm starting to get the hang of it. Currently, I'm building eye-tracking software as the principal architect and developer excellence lead at Tobii. My experience as a developer is mostly in systems programming and working in the embedded space with signal processing. However, I've also built distributed backend systems (before they were called microservices) and DDD-inspired desktop applications.</p> <p>For the past 20+ years, my native languages have been Python and C++. Lately, I've been flirting with Rust, and I'm loving it!</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html","title":"State of the Art Python in 2024","text":"<p>Software development is about making choices. But available options change and so do the tradeoffs. Are you up to date with the best practices for creating a Python application in 2024? Let\u2019s take a look at some great default choices.</p> TL;DR \u2014 State of the Art Python in 2024 <ol> <li>Use uv for dependency management (and everything else)</li> <li>Use ruff for formatting and linting</li> <li>Support Python 3.9 (or 3.13)</li> <li>Use a pyproject.toml file</li> <li>Use type hints</li> <li>Use pytest instead of unittest</li> <li>Use click instead of argparse</li> </ol>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-uv","title":"Use uv","text":"<p>During 2024 the tool \u2018uv\u2019 by Astral has taken the Python community by storm. Honestly, don\u2019t know how we ever did without it.</p> <p>uv is a bit like Rust\u2019s cargo, but for Python. It\u2019s a Swiss army knife for working with your project. It does dependency management, handles your virtual environments, installs the right Python version, packages and more.</p> <p>Instead of repeating all the guides in the official documentation, here are a few lovely things to try out:</p> <pre><code>uv init my-cli --app --package --python \"&gt;=3.9\"\ncd my-cli\nuv python install \"3.13\"  # Install a python\nuv run hello              # Run the 'main' func of the project\nuv add click              # Add a dependency\nuv add --dev pytest       # Add a development dependency\nuv tool install .         # Install the app as a standalone application\nuvx ruff format           # Format with ruff\n</code></pre> <p>I love Poetry, pipx, ruff, and hatch \u2014 and still use the latter two \u2014 but now uv is the only front end you need to work with Python. It just works and it\u2019s amazing \u2728</p> <p>NB: You should commit the <code>uv.lockfile</code> to get reproducible builds (and faster dependency resolution).</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-ruff","title":"Use ruff","text":"<p>The second amazing thing that Astral has created is the formatting and linting tool ruff. It\u2019s opinionated, very fast and you will never have to think about trivial formatting decisions ever again.</p> <pre><code>uvx ruff format\nuvx ruff check --fix\n</code></pre> <p>It\u2019s even fast enough to do formatting and auto-fixing in a git pre-commit hook! I suggest you run these two commands as a blocking PR check, and you will never have to discuss formatting in a code review ever again. And that\u2026 is AMAZING.</p> <p>The only default I disagree with is the line width. In 2024, 120 is the new 80.</p> <pre><code>[tool.ruff]\nline-length = 120\n</code></pre>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#support-python-39-or-313","title":"Support Python 3.9 (or 3.13)","text":"<p>I have three guidelines for picking what Python version to use in 2024:</p> <ol> <li>For public applications and libraries, you should support all of the actively supported Python versions out there. Right now, that is 3.9 to 3.13. This is a professional, grown-up (boring?) decision. Just do it.</li> <li>For internal applications, where you are in control of the execution environment, use only the latest supported version. This leverages performance benefits, improves environment cohesion and gives you access to the latest and greatest features.</li> <li>If you depend on a library that requires a more modern version than 3.9, be pragmatic about it. Either find a different library or accept limited reach for your own. Both are OK in different circumstances.</li> </ol> <p>Using the latest Python version is a free lunch: your application and your tests are automatically faster and cheaper to run. Often, this translates to lower costs for your cloud services and CI infrastructure.</p> <p>In practice you should add the default (3.13) version to a <code>.python-version</code> file in your project root. If you're nervous about 3.13 not having received it's first patch yet, staying on 3.12 for a few more weeks is fine.</p> <p>You should also be explicit about supporting older versions in your <code>pyproject.toml</code> file:</p> <pre><code>[proj]\n...\nrequires-python = \"&gt;=3.9\"\n</code></pre>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-a-pyprojecttoml","title":"Use a pyproject.toml","text":"<p>Always use a <code>pyproject.toml</code> file to specify dependencies, build options, and tool configuration. This is your one stop shop for all things meta when it comes to your project.</p> <p>This is sort of implied if you are using uv, so let\u2019s not linger on it.</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-type-hints","title":"Use Type Hints","text":"<p>Once a contentious issue, using type hints is now considered indispensable by most Python devs. In 2024, you should be using type annotations, especially in larger code bases.</p> <p>Make sure you pick a tool for type checking that works well with your IDE and CI environment and move on. Some good options are mypy, Pyright, pytype, and Pyre.</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-pytest","title":"Use pytest","text":"<p>Since you are writing unit tests (right?!) you need a test framework. The built-in unittest is mostly around for legacy and compatibility in 2024. What you should be using is pytest.</p> <p>Pytest has less boilerplate overhead for simple things (no required base class), and it brings more muscle for more complex tasks (parallel test execution &amp; parameterized tests).</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#use-click","title":"Use click","text":"<p>Command line interfaces are an absolute joy to develop in Python. Here are three libraries that you should use to step up your CLI game in 2024: click, yaspin and tqdm.</p> <p>Click is a general CLI library. Its main feature is command line argument handling. It does parsing, shell completion and boilerplate generation. Compared to argparse there\u2019s less to type and your code becomes more declarative (which is great).</p> <pre><code>import click\n\n@click.command()\n@click.argument(\"url\")\n@click.option(\"--api\", required=True, envvar=\"API_TOKEN\", help=\"An API Token\")\n@click.option(\"--validation/--no-validation\", is_flag=True, help=\"Perform validation?\")\ndef main(url, api, validation):\n    \"\"\"A great utility\"\"\"\n    pass\n</code></pre> <p>Gives us:</p> <pre><code>Usage: my-cli [OPTIONS] URL\n\n  A great utility\n\nOptions:\n  --api TEXT                      An API Token  [required]\n  --validation / --no-validation  Perform validation?\n  --help                          Show this message and exit.\n</code></pre> <p>But click also handles other common command line task, like ANSI color and stdin/stdout \u201c-\u201d support for filename arguments.</p> <pre><code>click.echo(click.style(\"\u2714\", fg=\"green\") + \" Yaaaaz!\")\n</code></pre> <p>Sometimes you need a bit more spice in your CLI. Use yaspin to add a terminal spinner and tqdm to add progress bars. Well isn\u2019t that just lovely?</p>"},{"location":"2024/10/28/state-of-the-art-python-in-2024.html#conclusion","title":"Conclusion","text":"<p>It\u2019s good to be a Python programmer in 2024. We have great libraries for all our basic needs like testing and CLI creation. By now, a consensus that type annotations are helpful has emerged, so you no longer need to argue with your coworkers about it. But more than anything, the tool uv is bringing a new level of convenience (and speed) to development workflows.</p> <p>I would like to extend a huge THANK YOU to Astral and all other Python devs that work on the projects I\u2018ve mentioned. It\u2019s never been more fun to write Python code, and it\u2019s because of the work you do. \ud83d\ude0d</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>EDIT: This topic caused quite a lot of discussion in my post on Reddit. It has 600 up-votes! Check it out if you want to know what many other Python devs think about the subject.</p>"},{"location":"2024/11/03/welcome-to-the-jungle.html","title":"Welcome to the Jungle","text":"<p>Your coding conventions, branching strategy, and review guidelines may seem like superficial policy hygiene. But these, along with seemingly random and disconnected activities like fixing a flaky unit test, are connected and can have a profound impact on how your team works with code.</p> <p>As a principal software architect and someone who cares deeply about how we develop software, I have mostly stopped writing down policies. Instead, I have started creating environments \u2014 jungles \u2014 where following a policy is the path of least resistance. By thinking about software development as a cultural ecology, you can unlock more flexible, efficient, and less bureaucratic ways of organizing software development.</p> <p>If you are a senior developer, architect, tech lead, or CTO, I invite you on an excursion. We\u2019ll travel winding paths through philosophy, biology, and social sciences to discover new ways of thinking about software development.</p> ![Trekking through rainforest](trekking.jpeg){ width=80% } <p>What is a software ecosystem? A global multitude of programs, libraries, and operating systems? A whirlpool of interactions between developers, teams, and organizations?</p> <p>Anthropologist Julian Steward coined the term cultural ecology in 1955 to describe the way that \u201ccultural change is induced by adaptations to the environment.\u201d Just like a biological ecosystem evolves and changes when different lifeforms interact in complex webs, societies evolve in relation to their cultural environments.</p> <p>The now famous quote from Rachel Carson\u2019s book Silent Spring: \u201cIn nature, nothing exists alone\u201d, applies to all ecologies, both biological and cultural.</p> <p>Software engineering is a particular and peculiar form of cultural ecology. A varied range of lifeforms \u2014 developers, scrum teams, companies, and open source projects \u2014 interact with an environment of programming languages, CI/CD systems, and office cubicles. The environment limits some behaviors but also presents opportunities for the life forms. But the influence is bi-directional; the activities of the inhabitants in the environment also change and create it. This reciprocal process extends to the interactions and actions of life forms vis-\u00e0-vis other life forms.</p>"},{"location":"2024/11/03/welcome-to-the-jungle.html#through-direct-collaboration-serendipitous-symbiosis-or-competition-in-software-development-ecologies-nothing-exists-alone","title":"<p>Through direct collaboration, serendipitous symbiosis, or competition; in software development ecologies, nothing exists alone.</p>","text":"<p>So, how is this way of looking at software engineering actually helpful? What does it provide beyond a mere and fanciful description of our practices?</p> <p>Unlike any other life forms, known from any ecology, we have the ability to reason about these processes in a way that makes it possible for us to also intervene in them. We are not merely evolving by reacting to our environment. We have the ability to get involved with intent. We can change our own culture and how we interact with each other by deliberately changing the environment.</p> <p>Let\u2019s consider a practical example: Fixing a flaky unit test. This can have a profound ecological impact and drive incredible behavioral change.</p> <p>Removing the flaky character of tests will make the state of the trunk (main branch) more predictable. There will be fewer false positive and negative reports from CI that undermine trust in the reported status. As a result, developers will be more prone to frequent integrations and shorter-lived feature branches. They won\u2019t need to worry about merging in a broken main branch. This, in turn, leads to fewer bugs introduced by complex merges and more code sharing and collaboration between different teams.</p> <p>A careful, deliberate intervention in the environment by an experienced steward of the ecosystem can have a profound positive impact and make the ecology thrive and flourish.</p> ![Architect in rainforest](architect.jpeg){ width=80% } <p>Another lesson that we ought to have learned from biological ecology is that interventions into an environment can have catastrophic consequences. In some cases, we have witnessed how an ignorant action has led to a full collapse of the ecosystem.</p> <p>This is also a risk in software development organizations. The blunt and autocratic introduction of a new \u201cincentives program\u201d by a CTO that permeates individual and quantitative achievements is a dangerous thing. We have witnessed many KPI-fueled wildfires and ecological disasters in software engineering ecologies.</p> <p>When a company connects salary and career advancement to how many tickets or story points a developer can complete in a given time, disaster is looming. Individual developers stop cooperating and instead start competing for the easy work. Important but difficult tasks remain unfinished. The quality of work diminishes as no one has time to do things properly or to refactor issues they discover.</p> <p>In short, an intervention into the environment has great potential but must be done attentively and with great care.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Changing an unfamiliar environment is especially dangerous but unfortunately very common. The old developer adage captures this experience: \u201cThe only thing worse than a manager who doesn\u2019t understand anything about development is a manager who understands a little bit.\u201d</p> <p>An experienced manager, tech lead, or architect acts as a gardener. When starting to tend to a new garden, they apply the \u201cOne Year Rule of Gardening\u201d: Don\u2019t change anything before you have seen one full season. Only tend to the weeds and attentively observe what grows when and where. Pay attention to where the shadows fall in spring and what spots are sheltered from autumn winds and where water accumulates after a summer rain.</p> <p>Translated to development, this amounts to observing how teams use different tools in different phases of a sprint or what communication patterns are exhibited when making a release. What are the thorny modules that no one likes tending to, and what API functions are always misunderstood by customers? Only start making small probing changes after observing a few of these cycles.</p> <p>With time, you will become an expert gardener and steward of the ecology. But even then, true mastery is displayed by only rarely resorting to larger changes. The best technical leaders bring about a thriving ecology through small changes to the environment. Understanding the complex web of interactions, cause and effect, and how various life forms will react allows you to make just the right small intervention at just the right time.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Let\u2019s investigate another complex technical issue through the lens of cultural ecology. Should you organize your code as a monorepo or divide it up into several smaller independent repositories?</p> <p>These two approaches represent quite different ecological environments for developers and subsequently drive different behaviors and adaptations.</p> <p>When Darwin visited the Gal\u00e1pagos Islands in 1835, he noticed how finches had evolved differently on different islands. The isolation of the islands caused a heterogeneity of life forms. This is also true for poly-repo ecologies. They tend to exhibit variations in coding style, build systems, branching strategy, etc. Being isolated, they also exhibit favorable traits like internal cohesion, less complex dependencies, and security by segmentation.</p> ![Paradise islands](islands.jpeg){ width=80% } <p>A monorepo, on the other hand, is a vast rainforest. Life-forms abound and can always immediately interact with each other, especially in watering holes and other nodal points (e.g., the build system). A healthy monorepo is, however, always internally structured in components and parts \u2014 it\u2019s not a giant ball of mud. In the jungle, some life forms inhabit the treetops and others the forest floor. In the monorepo, most developer teams spend their time in a niche, a fairly limited set of components and products.</p> <p>But since it\u2019s essentially one big environment, coding style, tooling, and code sharing are usually more homogeneous. This makes it easier for life forms that inhabit one niche to move into a new one if the opportunity presents itself (a developer moving from one project to another). Ecological interactions like symbiosis and cooperation drive behaviors that permeate communication across the entire organization in the monorepo ecology. The monorepo can be a counter force to Conways\u2019s Law.</p> <p>Larger and more diverse ecosystems are generally more resilient to shocks compared to smaller ones. An aquarium ecology is more fragile than an ocean. If the code in a monorepo is already built with five different compilers because of varying project needs, the shock of introducing another one is probably manageable.</p> <p>In contrast, a smaller repo that has only ever been built with one compiler will likely experience a large shock when a second one is introduced. There will be lots of new warnings, bugs, and incompatibilities discovered. In the poly-repo world, there is a different type of resilience. Each individual repository is typically less robust, but since they are disconnected, the shock waves don\u2019t spread and the impact is localized.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>In closing, I hope that you will find it useful to think about software development through the lens of cultural ecology.</p> <p>I hope that you will stop writing policy documents and instead start shaping the environment to drive behaviors. Next time, you might consider enforcing automatic code formatting in pre-merge CI instead of writing a code style document. If you need to write something, focus on explaining why the environment is landscaped the way it is and let the life forms loose to explore it on their own.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>EDIT: This article caused a lot of discussion in my post on Reddit. Check it out if you are interested in what other devs think about the topic.</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2024/11/06/steal-this-class.html","title":"Steal this Class","text":"<p>Class design in C++ is hard. Really, really, hard. I love C++ but, sadly, all the defaults are wrong.</p> <p>This means you have to add a lot of \u201cornamentation\u201d to a well-designed C++ class. This can seem bulky, so you might start second-guessing and questioning yourself, and it\u2019s easy to forget a thing or two.</p> <p>To make things worse, much of the advice on Stack Overflow and (LLM output trained on that advice) is outdated, incomplete, and just wrong.</p> <p>Since Ctrl-C, Ctrl-V is the de facto standard programming paradigm, and you are going to do it regardless, consider using these boilerplate classes. They are \u201ccopy-paste safe.\u201d They have the right defaults, and they are not missing some essential piece that will get you into trouble later.</p> ![Cute cat](take-this.jpg) <p>Of course, we have the C++ Core Guidelines. These are all the defaults and best practices you should be using. But, be honest, you\u2019re not going to read those, are you? These are the templates you have been looking for.</p>"},{"location":"2024/11/06/steal-this-class.html#a-plain-pod","title":"A Plain POD","text":"<pre><code>struct Point {\n  // A1 Use 'struct' for these, and only these, basic POD (Plain Old Data) types.\n  //    This reduces clutter by providing public visibility by default.\n\n  constexpr bool operator==(const Point&amp;) const noexcept = default;\n  // A2 Add the == operator (!= added implicitly) to make the type \"regular\"\n  // A3 Make the operators free functions in C++14 &amp; 17\n  // A4 Provide explicit operator!= in C++14 &amp; 17\n\n  float x{};\n  float y{};\n  // A5 Add {} to members of primitive type to make sure they are initialized.\n  // A6 Keep members after the functions. In case you need to convert it to a\n  //    class, this will produce a smaller git diff (less risk for conflicts).\n  // A7 Order members by \"type with largest alignment\" first, to keep the\n  //    struct small. Doubles first, then ints, then chars.\n};\n</code></pre>"},{"location":"2024/11/06/steal-this-class.html#basic-data-types-with-invariants","title":"Basic Data Types with Invariants","text":"<pre><code>class Circle {\n  // B1 Make anything with logic a class (not a struct)\npublic:\n  constexpr Circle() = default;\n  // B2 Always make basic data types default constructible to be \"regular\"\n  // B3 constexpr makes the data type more useful\n\n  constexpr explicit Circle(float radius) : Circle(Point{}, radius) {}\n  // B4 Use 'explicit' for all single argument constructors to prevent\n  //    unintentional implicit conversion.\n  // B5 Limit duplication in constructor bodies with delegating constructors\n\n  constexpr Circle(const Point&amp; center, float radius) :\n    center_(center), radius_(radius &lt; 0.0f ? 0.0f : radius) {}\n  // B6 Handle pre-condition violations and preserve class invariants\n  //    by truncation or throwing. Throw unless constructor is constexpr.\n\n  // B7 NO: constexpr Circle(float x, float y, float radius)\n  //    Don't offer this constructor to avoid confusion with argument order\n  //    at the call site, i.e. Circle{radius, x, y}\n\n  [[nodiscard]] constexpr const Point&amp; getCenter() const noexcept { return center_; }\n  // B8  Use both constexpr and const\n  // B9  Use [[nodiscard]] where it's clearly a bug to not use a return value\n  // B10 All logically non-mutating functions should be const\n\n  constexpr void setCenter(const Point&amp; center) { center_ = center; }\n  // B11 Setters can often not be noexcept since they might copy and allocate\n  //     In this case it would be fine, but not in general.\n\n  [[nodiscard]] constexpr float getRadius() const noexcept { return radius_; }\n\n  constexpr void setRadius(float radius) { radius_ = radius &lt; 0.0f ? 0.0f : radius; }\n  // B12 Preserve invariants in setters (or throw)\n  // B13 Take arguments as value in case they're small enough to be passed\n  //     in a register, i.e. all built-in types and smart pointers.\n\n  constexpr bool operator==(const Circle&amp;) const noexcept = default;\n  // B14 Add the == operator (!= added implicitly) to make the type \"regular\"\n  // B15 Make the operators free functions in C++14 &amp; 17\n  // B16 Provide explicit operator!= in C++14 &amp; 17\n\nprivate:\n  // B17 All mutable members are non const, non ref and private\n\n  Point center_{};\n  float radius_{};\n  // B18 Use trailing underscore to keep good parameter names in setter\n  //     function signatures.\n};\n</code></pre>"},{"location":"2024/11/06/steal-this-class.html#resource-owning-raii-types","title":"Resource Owning RAII Types","text":"<pre><code>class File {\n// C1 RAII types should be classes (not structs)\n\npublic:\n  [[nodiscard]] explicit File(const std::filesystem::path&amp; fileName)\n      : file_(std::fopen(fileName.c_str(), \"r\")) {\n    if (!file_) throw std::runtime_error(\"Failed to open file\");\n  }\n  // C2 [[nodiscard]] on constructors prevents forgetting to name the RAII object.\n  //    Especially important if the 'resource' is a side-effect, like a lock.\n  // C3 Use exceptions to signal errors\n  // C4 Make single-arg constructor 'explicit' to prevent implicit conversion.\n\n  ~File() noexcept { reset(); }\n  // C5 All destructors should be noexcept\n  // C6 Not 'virtual' since it is not meant as a base class\n  // C7 Use reset() function to avoid code duplication in move assignment\n\n  File(File&amp;&amp; other) noexcept : file_(std::exchange(other.file_, nullptr)) {}\n  // C8 Use std::exchange to leave the moved-from object in a clean state\n\n  File&amp; operator=(File&amp;&amp; other) &amp; noexcept {\n    if (this != &amp;other) {\n      reset();\n      std::swap(file_, other.file_);\n    }\n    return *this;\n  }\n  // C9  Can't use copy-and-swap idiom for move only types\n  // C10 reset() function to avoid code duplication here and in destructor\n  // C11 Release current resource before acquiring new one\n  // C12 Use std::swap leaves moved-from object in a clean state\n  // C13 Make move operations noexcept to work well with std::vector, etc.\n  // C14 Ref qualifier '&amp;' prevents move assignment to rvalue\n  // C15 Move assignment adds considerable complexity. Consider deleting it instead.\n\n  File(const File&amp;) = delete;\n  File&amp; operator=(const File&amp;) = delete;\n  // C16 RAII types should typically not be copyable. Be explicit (rule of 0/5).\n\nprivate:\n  void reset() noexcept {\n    if (file_) {\n      std::fclose(file_);\n      file_ = nullptr;\n    }\n  }\n  // C17 Avoid code duplication between dtor and move assignment operator.\n  // C18 Set file_ to nullptr to avoid double closing.\n\n  FILE* file_ = nullptr;\n  // C19 Initialize to nullptr in case there's an exception before\n  //     initializer-list assignment.\n};\n</code></pre>"},{"location":"2024/11/06/steal-this-class.html#polymorphic-types","title":"Polymorphic Types","text":"<pre><code>class Polygon {\n// D1 Interfaces should be classes (not structs)\n\npublic:\n  virtual ~Polygon() noexcept = default;\n  // D2 Add a virtual destructor to ensure derived class destructor is called\n  // D3 All destructors should be noexcept\n\n  [[nodiscard]] virtual double sumOfAngles() const noexcept = 0;\n  // D4 Pure virtual interface API functions\n  // D5 noexcept enforces noexcept in subclasses (use if desirable)\n  // D6 [[nodiscard]] and const for getters\n\nprotected:\n  Polygon() = default;\n  // D7 protected constructor to prevent instantiation of interface class\n  // D8 Not private to make default constructor available in subclass\n\nprivate:\n  Polygon(const Polygon&amp;) = delete;\n  Polygon&amp; operator=(const Polygon&amp;) = delete;\n  Polygon(Polygon&amp;&amp;) = delete;\n  Polygon&amp; operator=(Polygon&amp;&amp;) = delete;\n  // D9 remove value semantics for polymorphic class hierarchies\n};\n\nclass Triangle final : public Polygon {\n// D10 Inheritance should be public\n// D11 final prevents unintended extension of hierarchy\n\npublic:\n  Triangle() = default;\n  // D12 Default constructor here finds default constructor in base\n\n  virtual ~Triangle() noexcept = default;\n  // D13 virtual even if it's not necessary since class is final\n  //     If final is removed, this could prevent a hard to find bug.\n\n  [[nodiscard]] double sumOfAngles() const noexcept override { return 180.0; }\n  // D14 Use override. virtual is implied and not required\n  // D15 noexcept required by base class\n\n  // NO: Triangle(const Triangle&amp;) = delete;\n  // D16 No need to remove value semantics here since it's done in base\n};\n</code></pre> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Now, before you get too worked up and start yelling at the screen. I know, there are exceptions to almost all of the recommendations in this post. But they are exceptions. What I have presented are the safe and sane defaults. Your starting point for modern C++.</p> ![Hair of fire](hair-on-fire.jpeg) <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html","title":"Control is an Illusion Anyway...","text":"<p>Code review is an indispensable practice in any self-respecting software engineering organization. We get higher quality code and knowledge sharing. It's awesome. But, it\u2019s also not awesome. To be honest, it can be a nightmare. Sometimes we get blocked for days waiting for approval or end up in a never-ending context-switching game of review ping-pong.</p> <p>Today, we can't imagine living without version control or unit tests. We know they have a bit of an overhead, but the alternative is much worse. Much, much worse. Your code would roll over and crush you before you could say \"git rebase\" without these practices.</p> <p>After living with code reviews for many years, there is no way I'm ever giving that up either. It's just too valuable. But the pain felt is on a different order of magnitude compared to using git and writing unit tests. Getting blocked while waiting for a busy code owner can be incredibly frustrating. The only thing worse is getting pinged by impatient co-workers when you're in the zone, churning out code.</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#it-doesnt-have-to-be-this-way-though-but-theres-a-catch-the-other-way-is-terrifying-you-will-have-to-give-up-control","title":"<p>It doesn't have to be this way though, but there's a catch: the other way is terrifying. You will have to give up control.</p>","text":"<p>There's a way to make reviews rosy (or at least tolerable). But, before we get into all that, let's think about why we are doing code reviews in the first place.</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#eventually-consistent-quality","title":"Eventually Consistent Quality","text":"<p>If I were to check out your main branch right now, what quality of code would I get? Are there bugs? Is there technical debt? Are there parts in need of refactoring? In anything but a toy project, the answer to these questions is yes. Quality is not binary\u2014it's on a continuum.</p> <p>Unit testing and code reviews will increase quality. If not, then you're definitely doing it wrong. The more well-written tests you have and the more people looking at the code, the more issues will be found. Remember Linus's law: \"Given enough eyeballs, all bugs are shallow.\"</p> <p>But software engineering is about making hard decisions. There are always tradeoffs. How many eyeballs do you need before shipping? Or phrased differently, how much quality is enough quality? When do we enter the realm of diminishing returns, where development velocity and other costs outweigh further investments in quality?</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#there-are-two-major-quality-thresholds-to-consider-what-is-good-enough-to-merge-and-what-is-good-enough-to-release","title":"<p>There are two major quality thresholds to consider: What is good enough to merge? and What is good enough to release?</p>","text":"<p>For some projects, you can do genuine continuous deployments. In this case, the two thresholds are considered the same. The trunk is always in a releasable state. If this is within reach for your project, you should pour libations in thanks to your favorite deity; this is paradise. For most projects, however, it's not practical to make them the same. But we always strive to keep the merge and release quality levels as close as possible.</p> <p>Trunk quality should be high enough to not disrupt development. Code should compile, the unit tests should pass, and someone other than the PR author should have had a look at every change. I call it the \"no regrets\" level of quality: Developers should always be able to pull the main branch without regretting it.</p> <p>The trunk quality should be high enough that making a release is a simple, predictable, and low-risk activity. Even so, you might need to tick a few more boxes to get it shipped. For instance, you might need to execute some long-running nightly tests. Or you might need to run tests on prototype hardware, a very limited resource that can't be horizontally scaled in CI. Or you might have tests that need to run on some very expensive system, like a GPU cloud cluster.</p> <p>You should run these tests as often as you can afford to on your main branch. But running them on all PRs in a high-traffic repository won't work. You'll never be able to merge because you will be too far behind HEAD by the time they are finished (and you might bankrupt your company in the process).</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#the-fact-that-merge-quality-and-release-quality-are-slightly-different-is-actually-an-important-realization-when-it-comes-to-implementing-code-reviews","title":"<p>The fact that merge quality and release quality are slightly different is actually an important realization when it comes to implementing code reviews.</p>","text":"<p>We can start thinking about how much code review is required before merging and how much is required before releasing? It might not be exactly the same amount. We can start thinking about when to review, not just how and what. Aiming for eventual quality consistency is often an acceptable tradeoff for increased developer velocity.</p> <p>Let's get practical. To achieve rosy code reviews, you need something more than a review checklist; you need to consider your whole development and release process.</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#rosy-reviews","title":"Rosy Reviews","text":"<p>This is the review process that I introduced with my current employer, and we have been successfully practicing it for several years. It's used by a medium-sized department of the company with ~60 developers working in a monorepo while producing ~30 PRs/day.</p> <p>It focuses on the developer experience by reducing synchronization overhead (waiting) and by minimizing flow state interruptions. As a compromise, it takes a small step away from quality consistency on the main branch, towards eventual quality consistency.</p> <ol> <li>Practice shared code ownership, but don't be naive about it. Think: stewards, not owners.</li> <li>Require one review, but not necessarily by the code steward (owner).</li> <li>Encourage stewards to regularly review changes committed to components they care for.</li> <li>Review what matters. Compile with \"warnings as errors\". Enforce linting and strict auto formatting of code.</li> <li>Lean heavily on unit tests. Block PR merges until they pass. Scale CI appropriately so they run in less than 15 minutes.</li> <li>Run additional tests on every commit after merging. Scale CI appropriately so they run in less than 30 minutes.</li> <li>If the tests that run on trunk after the merge fail, always revert. Don't try to fix the issue while leaving the main branch broken.</li> <li>Run the gnarly tests (expensive and/or long-running) on the main branch as often as is permissible.</li> </ol>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#code-stewards-not-owners","title":"\ud83e\uddd9 Code Stewards, Not Owners","text":"<p>Code ownership is a bad idea. The owners become a synchronization barrier that slows down all other developers. It's also disruptive to the owners themselves since they need to act with low latency on review requests.</p> <p>This overhead will further disincentivize developers from doing safe and minor refactorings in code that they don't \"own.\" This is a missed opportunity for some everyday quality upkeep.</p> <p>You can still require a review from someone to reap those sweet benefits of code reviews. Leverage locality and request the review from someone in your team, but don't ask the same person every time.</p> <p>Naturally, some developers will know certain parts of the code better than others. They might even have a special responsibility for maintaining it in a good state. I call them Stewards, not Owners.</p> <p>Getting a review from a steward is desirable but not required. Instead, a steward can consider changes to their component at their own pace, without low latency interruptions. They can review changes even after they have been merged to the trunk. If the steward wants a change, they request a follow-up PR to address that. Worst case, the steward can request a revert, but in our experience, that almost never happens.</p> <p>If you are making significant or structural changes to a component, or if you are new to this particular area of the codebase, it's considered good etiquette to discuss the change with the steward beforehand. Leverage the CODEOWNERS feature of GitHub to get your Stewards automatically invited as lurkers to all PRs touching code that they care about.</p> <p>If you find this lack of control scary, stop hiring people that you don't trust to commit changes to your code in a responsible way.</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#raise-the-bar-for-merges","title":"Raise the Bar for Merges","text":"<p>This incremental reviews process must be used in combination with extensive automated testing. We are shifting some weight from reviews to testing when it comes to ensuring trunk quality.</p> <p>This is not a bad thing. Reviews can focus on higher-level and big-picture issues while most of the nitty-gritty bugs get squished by the tests before anyone other than the change author is involved.</p> <p>Doing \"lazy\" reviews like this, with optimistic merges is one of those: \"You must be this tall to ride\" type of things. If you don't have the tests, you don't get to do your reviews like this.</p> <p>Enforcing unconditional and automated formatting before merging is also key. If you are discussing code formatting in reviews, you need to stop. Pick a formatter: ruff, clang-format, rustfmt, or whatever and get on with more important things. If you are having a hard time implementing this because of differing opinions, you have a failure of technical leadership. Fix that problem first.</p>"},{"location":"2024/12/02/control-is-an-illusion-anyway.html#your-milage-may-vary","title":"\u26fd Your Milage May Vary","text":"<p>The Rosy Reviews process works well for us but it might not be for everyone. Our reviews latency is lower than in many other organization, but it still too high if you ask our developers. If you are curious about going down the eventual quality consistency route, here are some of the challenges we encountered. Consider if this is something that might need special attention in your organization.</p> ![Clueless Revierer](clueless-reviewer.jpeg){ width=50% } <p>It doesn't work without reliable tests. If you do \"lazy\" reviews without tests, you're back to yolo land. That's only fun until it breaks.</p> <p>The reliable part of \"reliable tests\" is important. If you have flaky tests as a gate to pass before merging, it will drive your developers crazy with frustration. If you have flaky tests running after a merge, you can't say for sure if you should revert a commit that fails. This leaves the trunk in limbo-land between a red and green state. Developers can't trust that they can pull main with \"no regrets\".</p> <p>Working on our tests has been, and still is, one of our major investments that makes this way of doing reviews even possible.</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2024/12/18/git-beyond-the-basics.html","title":"Git - Beyond the Basics","text":"<p>How well do you know Git? Many of us use it daily and pick up the basics as we go. After a few years, you might start to think that you know Git pretty well. But there are more things in the Git man pages than are dreamt of in your philosophy...</p> <p>For instance, if you are not using <code>git maintenance</code> or <code>worktree</code>, you are missing out. This blog post is for those who would like to explore Git beyond the basics.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Much of the content in this post is straight out of the 2024 FOSDEM talk \"So You Think You Know Git?\" by the amazing Scott Chacon. Here is that talk and the follow-up \"Part 2\" from DevWorld 2024. I have cherry-picked the parts that I found most useful from his presentations and mixed them up with some of my own favorite Git features.</p> <p>Before we get started, make sure you have the latest version of git installed: https://git-scm.com/ Some of the things covered in this post are relatively new. If you haven't updated your Git installation for a few years, now is the time.</p> <p>Staying true to Scott Chacon's \"shotgun buffet\" presentation style, here is a bunch of useful Git tips for you, in no particular order. Let's go!</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-log","title":"git log","text":"<p>Let's start by setting up some nice log formatting and default arguments with a <code>git l</code> alias:</p> <pre><code>git config --global alias.l \"log --pretty=format:'%C(#cccc00)%h %Cred%ad %Creset%&lt;(60,trunc)%s%C(auto)%d %C(magenta)%&lt;(15,trunc)%an' --date=format:'%y%m%d'\"\n</code></pre> ![zlib gitlog color](git-log.png){ width=100% } <p>With formatting out of the way, let's look at some other nice <code>git log</code> options.</p> <p>To figure out not just how, but when a function changed, you can use the <code>-L</code> option with git log:</p> <pre><code>git log -L :compress2:compress.c\n</code></pre> <p>This will list all commits (and display diffs) for when the <code>compress2</code> function in the <code>compress.c</code> file changed. Git uses a heuristic to figure out where the function starts and ends, and it might not work 100%. Sometimes you will see a few \"extra\" revs listed in the log, but it's still quite useful.</p> <p>Another useful way to search your history is with the <code>-S</code> option. It looks for additions or deletions of a specific string:</p> <pre><code>git log -S API_KEY      # Show matching commits\ngit log -p -S API_KEY   # Show diff for matching commits\n</code></pre> <p>This will show all the commits that add or remove the \"API_KEY\" string. If you are horrified by what you find after running that command, perhaps consider GitHub Secret Scanning?</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-blame","title":"git blame","text":"<p>The <code>git blame</code> command shows you when and who last modified each line of a file. This is useful to understand who to ask about some piece of code or what the context was for a change.</p> <p>But there is a problem. Sometimes a line changes in not so interesting ways. Perhaps someone removed a trailing whitespace (you should be using pre-commit to avoid that by the way). Or a line might have been moved around. In these cases, the plain <code>git blame</code> will only show the most recent, i.e. the not so interesting change. The origin of the line is obscured.</p> <p>There are a few things you can do to improve the situation. For starters, use: <code>git blame -w -C</code>. This ignores whitespaces (<code>-w</code>) and looks for lines that were moved or copied from other files in the same commit (<code>-C</code>).</p> <p>You can additionally provide the <code>-C</code> option two or three times to detect even \"deeper\" moving of lines by looking further back into history. In my experience though, using more than one <code>-C</code> makes the command frustratingly slow for anything but small repos with a short history.</p> <p>Here is the deep-blame alias I use:</p> <pre><code>git config --global alias.dblame 'blame -w -C'\n</code></pre> <p>Another useful blame feature is the ability to ignore specific revisions by adding a <code>.git-blame-ignore-revs</code> file. Without this, major formatting changes will make blame mostly useless since all blame commands will only show the formatting commit. Great if you are adopting ruff for your Python code.</p> <p>Start using the file in your repository with:</p> <pre><code>git config --global blame.ignoreRevsFile .git-blame-ignore-revs\n</code></pre> <p>And this is some sample <code>.git-blame-ignore-revs</code> content:</p> <pre><code>d01ecec5367d4475d4a8ff08ac74088cc6423ba6 # Global clang-format with new style\n68af25be0dc7d77e2cb99f3c9cabe1c96cf71149 # Switching from black to ruff\n63b5fa235c5f4ec01fcb329972d2fa51682e7d75 # Consistent \"west const\"\n</code></pre> <p>While we are on the subject of <code>git blame</code>, there is also the <code>--color-by-age</code> option that highlights recent changes with an accent color. Useful to see recent changes \"at a glance\".</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-branch","title":"git branch","text":"<p>The git branch command will list local branches in alphabetical order. That's not helpful, at least if you have many local branches. What you want is to sort them by recent activity. Change the default:</p> <pre><code>git config --global branch.sort -committerdate\n</code></pre> <p>While we're at it, let's add some color and a bit more context to the branch output. This is my <code>git b</code> alias and the rich output it produces:</p> <pre><code>git config --global alias.b \"branch --format='%(color:#cccc00)%(objectname:short) %(color:red)%(committerdate:short) %(color:bold white)%(refname:short)'\"\n</code></pre> ![branch alias](git-branch.png){ width=60% }"},{"location":"2024/12/18/git-beyond-the-basics.html#git-push-force-with-lease","title":"git push --force-with-lease","text":"<p>If you have worked long enough with Git, you will have discovered the tempting foot-gun <code>git push --force</code>. If you have discovered it, you might also have successfully discharged it into your foot and lost some work.</p> <p>It usually goes like this: You do your work, commit and push it. Then you realize you forgot to rebase on top of main, so you do that and try to push again. This time, Git will complain since you are rewriting history on the remote. But you think that this is exactly what you wanted to do, so you try again with <code>git push --force</code>. This time, your rebased commits are up and everything is great. Or is it?</p> <p>While you were rebasing, your coworker pushed a commit on top of your original change. Since you didn't fetch before rebasing, your force push obliterated their work and it is lost, like tears in the rain. Actually, the change is still locally with your coworker, so you can probably fix this pretty easily. But it's not nice to obliterate commits from other people. So let's try to avoid that.</p> <p>Enter <code>git push --force-with-lease</code>. This does what you want but doesn't let you shoot yourself in the foot. It only allows the force push if the remote history is the same as the local history, i.e., it works like a regular force push as long as there are no coworker commits in the way.</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-maintenance","title":"git maintenance","text":"<p>To keep Git performing well, there is some maintenance required. The internal data representation must be pruned and compressed.</p> <p>Instead of letting these tasks piggyback on other Git commands (making them take longer), we can enable background repo maintenance:</p> <pre><code>git maintenance start\n</code></pre> <p>This is one of those \"set and forget\" type of things. Enable this in your active repos and Git will just be faster. Just do it.</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-rerere","title":"git rerere","text":"<p>Resolving merge conflicts is nobody's favorite pastime. So when you get the exact same merge conflict again, you wish that Git would have learned how it should be resolved and get on with it. If you enable rerere (reuse recorded resolution), Git will do just that:</p> <pre><code>git config --global rerere.enabled true\n</code></pre> <p>This problem is more common if you have long-lived feature branches or workflows where you do a lot of rebasing and cherry-picking. But since there is almost no cost to enable it, just do it.</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-and-bash","title":"git and bash","text":"<p>If you are using Git from the terminal, you might consider adding a bit of ornamentation to your prompt. This is my favorite and it works well for bash.</p> ![zlib gitlog color](git-prompt.png){ width=50% } <p><pre><code>git clone https://github.com/magicmonty/bash-git-prompt.git ~/.bash-git-prompt --depth=1\n</code></pre> Then and add this to your <code>~/.bashrc</code>:</p> <pre><code>if [ -f \"$HOME/.bash-git-prompt/gitprompt.sh\" ]; then\n    GIT_PROMPT_ONLY_IN_REPO=1\n    GIT_PROMPT_THEME=Single_line_Solarized\n    source \"$HOME/.bash-git-prompt/gitprompt.sh\"\nfi\n</code></pre>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-addresetcheckout-p","title":"git add/reset/checkout -p","text":"<p>Sometimes (or all the time?) we find ourselves multitasking. While working on one thing, we find some minor unrelated \"wart\" and fix it. That's great, but it's really not part of the original task. Ideally, it should end up in a different commit.</p> <p>If the \"bonus\" changes are made to different files, we can just stage them separately. But more often than not, the \"bonus\" and the original task changes are to the same file.</p> <p>This is where <code>git add -p</code> comes in handy. You can stage parts of a file and leave other parts unstaged. You can also unstage with <code>git reset -p</code> and even revert changes with <code>git checkout -p</code>.</p> <p>Git will step through all changes and ask you what to do with them. The caveat is that when you run the unit tests locally, they will run on both staged and unstaged changes, so you might not notice if your partial add broke something until tests are running in CI.</p>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-worktrees","title":"git worktrees","text":"<p>If the casual multitasking of <code>git add -p</code> is not enough, you should consider worktrees. This is how you check out several branches side by side in different directories without cloning your repo multiple times. All the blobs and refs are then shared between the two directories. Here is how to check out a new branch in a new-repo-dir directory:</p> <pre><code>git worktree add -b new-branch ../new-repo-dir\n</code></pre>"},{"location":"2024/12/18/git-beyond-the-basics.html#git-rebase-autosquash","title":"git rebase --autosquash","text":"<p>GitHub's pull request concept (which isn't really a Git concept) is very nice for collaborating in a repository, especially if you want to do code reviews. The squash merge strategy is the way to go in this situation.</p> <p>But sometimes I find myself working alone in a Git repo and the pull request workflow is just a lot of overhead. Instead, I tend to prefer a rebase-centered workflow. Create a few commits on a branch as you work, then tidy them up with <code>git rebase --interactive</code> before pushing. This lets you combine, split, or reword commits as appropriate to make them coherent and cohesive.</p> <p>Nice! But if you make a change that you know should have been part of an earlier commit, you can save yourself some work in the interactive rebase phase by committing it as a fixup directly.</p> <p>Consider this situation with two commits:</p> <pre><code>echo \"foo\" &gt; foo\ngit add foo\ngit commit -m \"Adding a foo file\"\n\n\"bar\" &gt; bar\ngit add bar\ngit commit -m \"Adding a bar file\"\n</code></pre> <p>You then proceed to work and realize that what you are doing should be part of the first commit. You could try to remember this and fix it when you do your interactive rebase later. But you don't have to. You can do a fixup and stay in your development flow. Later, you autosquash the fixup commits and do any further interactive rebasing (if there is still something to do).</p> ![fixup commit](fixup.png){ width=60% } <pre><code>echo \"fubar\" &gt;&gt; foo\ngit add -u\ngit commit --fixup=&lt;commit hash&gt; # 9f5e01c\n\ngit rebase --autosquash\n</code></pre>"},{"location":"2024/12/18/git-beyond-the-basics.html#github-linguist","title":"github-linguist","text":"<p>Maybe the least useful advice in this blog post is also not a git native topic, but a GitHub specific one. But since I know this really trigger some people's OCD, I consider it a public health service. I'm referring to the GitHub language stats for you repo...</p> ![github-linguist](linguist.png){ width=80% } <p>Some times, the tool that GitHub uses <code>github-linguist</code> (you can run it locally) need a little help. You can provide hints in a <code>.gitattributes</code> file.</p> <pre><code>camera/test-images/*.h   linguist-generated\npartner-libs/*           linguist-vendored\n*.h                      linguist-language=C\n</code></pre> <p>This example will prevent generated header's with binary image data from being included. And it will ignore \"vendored in\" thirdparty libraries. It will also fix the common issues miss-classifying C as Objective-C</p> <p>While you are editing your <code>.gitattributes</code> file, go ahead and add <code>* text=auto</code> to it to make git take care of line ending differences between Linux and Windows so you don't have to hope that all devs setup their <code>core.autocrlf</code> config in the right way.</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2024/12/25/a-simple-elf.html","title":"A Simple ELF","text":"<p>Let's write a simple program for Linux. How hard can it be? Well, simple is the opposite of complex, not of hard, and it is surprisingly hard to create something simple. What is left when we get rid of the complexity from the standard library, all the modern security features, debugging information, and error handling mechanisms?</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Let's start with something complex:</p> <pre><code>#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello Simplicity!\\n\");\n}\n</code></pre> <p>Wait, what?! It doesn't look very complex, does it... Hmm, let's compile it and take a look:</p> <pre><code>$ gcc -o hello hello.c\n$ ./hello\nHello Simplicity!\n</code></pre> <p>Still looks pretty simple, right? Wrong! While this might be familiar territory and easy to comprehend, the program is far from simple. Let's take a look behind the curtain.</p> <pre><code>$ objdump -t hello\n\nhello:     file format elf64-x86-64\n\nSYMBOL TABLE:\n0000000000000000 l    df *ABS*  0000000000000000              Scrt1.o\n000000000000038c l     O .note.ABI-tag  0000000000000020              __abi_tag\n0000000000000000 l    df *ABS*  0000000000000000              crtstuff.c\n0000000000001090 l     F .text  0000000000000000              deregister_tm_clones\n00000000000010c0 l     F .text  0000000000000000              register_tm_clones\n0000000000001100 l     F .text  0000000000000000              __do_global_dtors_aux\n0000000000004010 l     O .bss   0000000000000001              completed.0\n0000000000003dc0 l     O .fini_array    0000000000000000              __do_global_dtors_aux_fini_array_entry\n0000000000001140 l     F .text  0000000000000000              frame_dummy\n0000000000003db8 l     O .init_array    0000000000000000              __frame_dummy_init_array_entry\n0000000000000000 l    df *ABS*  0000000000000000              hello.c\n0000000000000000 l    df *ABS*  0000000000000000              crtstuff.c\n00000000000020f8 l     O .eh_frame  0000000000000000              __FRAME_END__\n0000000000000000 l    df *ABS*  0000000000000000\n0000000000003dc8 l     O .dynamic   0000000000000000              _DYNAMIC\n0000000000002018 l       .eh_frame_hdr  0000000000000000              __GNU_EH_FRAME_HDR\n0000000000003fb8 l     O .got   0000000000000000              _GLOBAL_OFFSET_TABLE_\n0000000000000000       F *UND*  0000000000000000              __libc_start_main@GLIBC_2.34\n0000000000000000  w      *UND*  0000000000000000              _ITM_deregisterTMCloneTable\n0000000000004000  w      .data  0000000000000000              data_start\n0000000000000000       F *UND*  0000000000000000              puts@GLIBC_2.2.5\n0000000000004010 g       .data  0000000000000000              _edata\n0000000000001168 g     F .fini  0000000000000000              .hidden _fini\n0000000000004000 g       .data  0000000000000000              __data_start\n0000000000000000  w      *UND*  0000000000000000              __gmon_start__\n0000000000004008 g     O .data  0000000000000000              .hidden __dso_handle\n0000000000002000 g     O .rodata    0000000000000004              _IO_stdin_used\n0000000000004018 g       .bss   0000000000000000              _end\n0000000000001060 g     F .text  0000000000000026              _start\n0000000000004010 g       .bss   0000000000000000              __bss_start\n0000000000001149 g     F .text  000000000000001e              main\n0000000000004010 g     O .data  0000000000000000              .hidden __TMC_END__\n0000000000000000  w      *UND*  0000000000000000              _ITM_registerTMCloneTable\n0000000000000000  w    F *UND*  0000000000000000              __cxa_finalize@GLIBC_2.2.5\n0000000000001000 g     F .init  0000000000000000              .hidden _init\n</code></pre> <p>That's a lot of symbols! Actually, as far as symbol tables go, this one is quite modest. Any non-trivial program will have many more symbols, but still, what are they all for? We're just printing a string!</p> <p>We recognize our <code>main</code> function in the <code>.text</code> segment at address <code>0x1149</code>. But where is the <code>printf</code> function?</p> <p>It turns out that for simple cases, where there is no formatting work required by <code>printf</code>, GCC optimizes the code and replaces it with the simpler <code>puts@GLIBC_2.2.5</code> from libc. The address is all zeros since the symbol is undefined (<code>*UND*</code>). It will be resolved when the program is loaded together with the dynamic libc.so library as we run it.</p> <pre><code>0000000000001149 g     F .text  000000000000001e              main\n0000000000000000       F *UND*  0000000000000000              puts@GLIBC_2.2.5\n</code></pre> <p>Let's keep digging. What sections are there in the program? The only data we have is the hardcoded string and its length. Surely we only need a <code>.text</code> section? Let's see what we got:</p> <pre><code>$ objdump -h hello\n\nhello:     file format elf64-x86-64\n\nSections:\nIdx Name          Size      VMA               LMA               File off  Algn\n  0 .interp       0000001c  0000000000000318  0000000000000318  00000318  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  1 .note.gnu.property 00000030  0000000000000338  0000000000000338  00000338  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  2 .note.gnu.build-id 00000024  0000000000000368  0000000000000368  00000368  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  3 .note.ABI-tag 00000020  000000000000038c  000000000000038c  0000038c  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  4 .gnu.hash     00000024  00000000000003b0  00000000000003b0  000003b0  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  5 .dynsym       000000a8  00000000000003d8  00000000000003d8  000003d8  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  6 .dynstr       0000008d  0000000000000480  0000000000000480  00000480  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  7 .gnu.version  0000000e  000000000000050e  000000000000050e  0000050e  2**1\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  8 .gnu.version_r 00000030  0000000000000520  0000000000000520  00000520  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  9 .rela.dyn     000000c0  0000000000000550  0000000000000550  00000550  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n 10 .rela.plt     00000018  0000000000000610  0000000000000610  00000610  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n 11 .init         0000001b  0000000000001000  0000000000001000  00001000  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 12 .plt          00000020  0000000000001020  0000000000001020  00001020  2**4\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 13 .plt.got      00000010  0000000000001040  0000000000001040  00001040  2**4\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 14 .plt.sec      00000010  0000000000001050  0000000000001050  00001050  2**4\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 15 .text         00000107  0000000000001060  0000000000001060  00001060  2**4\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 16 .fini         0000000d  0000000000001168  0000000000001168  00001168  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n 17 .rodata       00000011  0000000000002000  0000000000002000  00002000  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n 18 .eh_frame_hdr 00000034  0000000000002014  0000000000002014  00002014  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n 19 .eh_frame     000000ac  0000000000002048  0000000000002048  00002048  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n 20 .init_array   00000008  0000000000003db8  0000000000003db8  00002db8  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 21 .fini_array   00000008  0000000000003dc0  0000000000003dc0  00002dc0  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 22 .dynamic      000001f0  0000000000003dc8  0000000000003dc8  00002dc8  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 23 .got          00000048  0000000000003fb8  0000000000003fb8  00002fb8  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 24 .data         00000010  0000000000004000  0000000000004000  00003000  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 25 .bss          00000008  0000000000004010  0000000000004010  00003010  2**0\n                  ALLOC\n 26 .comment      0000002b  0000000000000000  0000000000000000  00003010  2**0\n                  CONTENTS, READONLY\n</code></pre> <p>Ok, so that's definitely complex. It's not just a simple <code>.text</code> section. There are a LOT of them.</p> <p>This is too much to deal with right now. Where does the program even start? It starts with <code>main</code>, right? Wrong again!</p> <pre><code>$ objdump -f hello\n\nhello:     file format elf64-x86-64\narchitecture: i386:x86-64, flags 0x00000150:\nHAS_SYMS, DYNAMIC, D_PAGED\nstart address 0x0000000000001060\n</code></pre> <p>The \"start address\" (also known as the entry point), is <code>_start</code>, not <code>main</code>. This mystery function at <code>0x1060</code> must call our <code>main</code> somehow, but where does it come from!?</p> <pre><code>0000000000001060 g     F .text  0000000000000026              _start\n</code></pre> <p>Let's start simplifying the program. As we peel off complexity, we will get a chance to focus on understanding a few things at a time.</p>"},{"location":"2024/12/25/a-simple-elf.html#life-without-libc","title":"Life without libc","text":"<p>A major source of complexity in our program comes from the standard libraries. They are used for printing the string and initializing the program. Let's get rid of them.</p> <p>Easy enough, just compile with: <code>-nostdlib</code>.</p> <p>Unfortunately, that means we no longer have access to the <code>printf</code> (or the <code>puts</code>) function. That's unfortunate since we still want to print \"Hello Simplicity!\".</p> <p>It also means we will lose the <code>_start</code> function. It is provided by the C runtime library (CRT) to perform some initialization (like clearing the <code>.bss</code> segment) and call our <code>main</code> function. Since we still need our <code>main</code> to be executed, we will have to do something about that.</p> <p>Fortunately, we can provide our own entry point with <code>-Wl,-e,&lt;function_name&gt;</code>. We could specify <code>main</code> as our entry point directly, but that would mean treating it as <code>void main()</code> instead of <code>int main()</code>. The entry point doesn't return anything. I feel that changing the signature of <code>main</code> is one bridge too far; let's instead create our own <code>void startup()</code> function that calls <code>main</code>.</p> <p>For writing to <code>stdout</code>, we resort to the <code>syscall</code> assembly instruction. This instruction is how we ask the Linux kernel to do things for us. In this particular case, we would like to execute the <code>write</code> syscall to write a string to <code>stdout</code> (file descriptor = 1). Later on, we also want to call <code>exit</code> to terminate the process.</p> <p>When calling the <code>syscall</code> instruction, we pass the syscall number in the <code>rax</code> register and the arguments in registers <code>rdi</code>, <code>rsi</code>, and <code>rdx</code>. The <code>write</code> syscall has number <code>0x01</code> and the <code>exit</code> syscall has number <code>0x3c</code>.</p> <p>These are their C signatures:</p> <pre><code>ssize_t write(int fildes, const void *buf, size_t nbyte);\nvoid exit(int status);\n</code></pre> <p>and this is our new program <code>hello-syscall.c</code>:</p> <pre><code>int main() {\n\n  volatile const char message[] = \"Hello Simplicity!\\n\";\n  volatile const unsigned long length = sizeof(message) - 1;\n\n  // write(1, message, length)\n  asm volatile(\"mov $1, %%rax\\n\"                // write syscall number (0x01)\n               \"mov $1, %%rdi\\n\"                // Stdout file descriptor (0x01)\n               \"mov %0, %%rsi\\n\"                // Message buffer\n               \"mov %1, %%rdx\\n\"                // Buffer length\n               \"syscall\"                        // Make the syscall\n               :                                // No output operands\n               : \"r\"(message), \"r\"(length)      // Input operands\n               : \"%rax\", \"%rdi\", \"%rsi\", \"%rdx\" // Clobbered registers\n  );\n\n  return 0;\n}\n\nvoid startup() {\n\n  volatile unsigned long status = main();\n\n  // exit(status)\n  asm volatile(\"mov $0x3c, %%rax\\n\" // exit syscall number (0x3c)\n               \"mov %0, %%rdi\\n\"    // exit status\n               \"syscall\"            // Make the syscall\n               :                    // No output operands\n               : \"r\"(status)        // Input operands\n               : \"%rax\", \"%rdi\"     // Clobbered registers\n  );\n}\n</code></pre> <p>In case you are wondering, the <code>volatile</code> keyword is required to prevent GCC from optimizing away the variables. And <code>unsigned long</code> is used instead of <code>int</code> to match the size of the <code>r__</code> 64-bit registers.</p> <p>We build it like so:</p> <pre><code>gcc -Wl,-entry=startup -nostdlib -o hello-nostd hello-syscall.c\n</code></pre> <p>Is this really simpler than before? Well, yes!</p> <p>It might not be easier to understand unless you are accustomed to assembly language, syscalls, and custom entry points. But simple is not synonymous with easy. Simple is the opposite of complex. Complex things are intrinsically hard to understand, no matter how much you know. Simple things are only hard to understand until you have acquired the appropriate skills. Rich Hickey explains this eloquently in his 2011 talk \"Simple Made Easy\".</p> <p>Still not convinced that we have actually made the program simpler? Let's take a look at the symbols and sections:</p> <pre><code>$ objdump -h -t hello-nostd\n\nSections:\nIdx Name          Size      VMA               LMA               File off  Algn\n  0 .interp       0000001c  0000000000000318  0000000000000318  00000318  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  1 .note.gnu.property 00000020  0000000000000338  0000000000000338  00000338  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  2 .note.gnu.build-id 00000024  0000000000000358  0000000000000358  00000358  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  3 .gnu.hash     0000001c  0000000000000380  0000000000000380  00000380  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  4 .dynsym       00000018  00000000000003a0  00000000000003a0  000003a0  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  5 .dynstr       00000001  00000000000003b8  00000000000003b8  000003b8  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  6 .text         0000007f  0000000000001000  0000000000001000  00001000  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  7 .eh_frame_hdr 0000001c  0000000000002000  0000000000002000  00002000  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  8 .eh_frame     00000058  0000000000002020  0000000000002020  00002020  2**3\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\n  9 .dynamic      000000e0  0000000000003f20  0000000000003f20  00002f20  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n 10 .comment      0000002b  0000000000000000  0000000000000000  00003000  2**0\n                  CONTENTS, READONLY\n\nSYMBOL TABLE:\n0000000000000000 l    df *ABS*  0000000000000000 hello-syscall.c\n0000000000000000 l    df *ABS*  0000000000000000\n0000000000003f20 l     O .dynamic   0000000000000000 _DYNAMIC\n0000000000002000 l       .eh_frame_hdr  0000000000000000 __GNU_EH_FRAME_HDR\n0000000000001050 g     F .text  000000000000002f startup\n0000000000004000 g       .dynamic   0000000000000000 __bss_start\n0000000000001000 g     F .text  0000000000000050 main\n0000000000004000 g       .dynamic   0000000000000000 _edata\n0000000000004000 g       .dynamic   0000000000000000 _end\n</code></pre> <p>There's still a lot going on here, but at least it now fits on one screen. As expected, <code>objdump -f</code> gives us a new start address: <code>0x1050</code>. It's our <code>startup</code> function!</p> <p>Let's continue simplifying!</p>"},{"location":"2024/12/25/a-simple-elf.html#life-without-pie","title":"Life without PIE","text":"<p>For the last 20 years, your programs have been loaded into memory at random addresses as a security mitigation. ASLR (Address Space Layout Randomization) makes it harder to write exploits since the shellcode can't jump to hardcoded destinations. It also means jumps in your regular programs can't be hardcoded.</p> <p>By default, programs on modern systems are built as Position Independent Executables (PIE). Addresses are resolved when the program is loaded into memory. It's great for security, but it adds complexity. Let's get rid of it with: <code>-no-pie</code>.</p> <p>To further unclutter our assembly code, we turn off some more safety features with <code>-fcf-protection=none</code> and <code>-fno-stack-protector</code>. We also get rid of some metadata generation with <code>-Wl,--build-id=none</code> and some debugger-friendly stack unwinding info with <code>-fno-unwind-tables</code> and <code>-fno-asynchronous-unwind-tables</code>.</p> <pre><code>gcc -no-pie \\\n    -nostdlib \\\n    -Wl,-e,startup \\\n    -Wl,--build-id=none \\\n    -fcf-protection=none \\\n    -fno-stack-protector \\\n    -fno-asynchronous-unwind-tables \\\n    -fno-unwind-tables \\\n    -o hello-nostd-nopie hello.c\n</code></pre> <p>We are now down to this:</p> <pre><code>$ objdump -h -t hello-nostd-nopie\n\nhello-nostd-nopie:     file format elf64-x86-64\n\nSections:\nIdx Name          Size      VMA               LMA               File off  Algn\n  0 .text         00000077  0000000000401000  0000000000401000  00001000  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  1 .comment      0000002b  0000000000000000  0000000000000000  00001077  2**0\n                  CONTENTS, READONLY\nSYMBOL TABLE:\n0000000000000000 l    df *ABS*  0000000000000000 hello-syscall.c\n000000000040104c g     F .text  000000000000002b startup\n0000000000402000 g       .text  0000000000000000 __bss_start\n0000000000401000 g     F .text  000000000000004c main\n0000000000402000 g       .text  0000000000000000 _edata\n0000000000402000 g       .text  0000000000000000 _end\n</code></pre> <p>Did you notice how the symbol addresses changed with <code>-no-pie</code>? Before, they were relative, waiting for some offset to be added at load time. Now, they are absolute, and <code>main</code> will really be at <code>0x00401000</code>.</p> <pre><code>$ gdb hi\n(gdb) break main\nBreakpoint 1 at 0x401004\n(gdb) run\nBreakpoint 1, 0x0000000000401004 in main ()\n</code></pre> <p>Phew! We are finally approaching something simple-ish. Now, our entire program even fits on one screen:</p> <pre><code>$ objdump -d -M intel hello-nostd-nopie\n\nDisassembly of section .text:\n\n0000000000401000 &lt;main&gt;:\n  401000:   55                      push   rbp\n  401001:   48 89 e5                mov    rbp,rsp\n  401004:   48 b8 48 65 6c 6c 6f    movabs rax,0x6953206f6c6c6548\n  40100b:   20 53 69\n  40100e:   48 ba 6d 70 6c 69 63    movabs rdx,0x79746963696c706d\n  401015:   69 74 79\n  401018:   48 89 45 e0             mov    QWORD PTR [rbp-0x20],rax\n  40101c:   48 89 55 e8             mov    QWORD PTR [rbp-0x18],rdx\n  401020:   66 c7 45 f0 21 0a       mov    WORD PTR [rbp-0x10],0xa21\n  401026:   c6 45 f2 00             mov    BYTE PTR [rbp-0xe],0x0\n  40102a:   48 c7 45 d8 12 00 00    mov    QWORD PTR [rbp-0x28],0x12\n  401031:   00\n  401032:   4c 8b 45 d8             mov    r8,QWORD PTR [rbp-0x28]\n  401036:   48 8d 4d e0             lea    rcx,[rbp-0x20]\n  40103a:   48 c7 c0 01 00 00 00    mov    rax,0x1\n  401041:   48 c7 c7 01 00 00 00    mov    rdi,0x1\n  401048:   48 89 ce                mov    rsi,rcx\n  40104b:   4c 89 c2                mov    rdx,r8\n  40104e:   0f 05                   syscall\n  401050:   b8 00 00 00 00          mov    eax,0x0\n  401055:   5d                      pop    rbp\n  401056:   c3                      ret\n\n0000000000401057 &lt;startup&gt;:\n  401057:   55                      push   rbp\n  401058:   48 89 e5                mov    rbp,rsp\n  40105b:   48 83 ec 10             sub    rsp,0x10\n  40105f:   b8 00 00 00 00          mov    eax,0x0\n  401064:   e8 97 ff ff ff          call   401000 &lt;main&gt;\n  401069:   48 98                   cdqe\n  40106b:   48 89 45 f8             mov    QWORD PTR [rbp-0x8],rax\n  40106f:   48 8b 55 f8             mov    rdx,QWORD PTR [rbp-0x8]\n  401073:   48 c7 c0 3c 00 00 00    mov    rax,0x3c\n  40107a:   48 89 d7                mov    rdi,rdx\n  40107d:   0f 05                   syscall\n  40107f:   90                      nop\n  401080:   c9                      leave\n  401081:   c3                      ret\n</code></pre> <p>You can see the <code>startup</code> function calling <code>main</code>, the two syscalls, and the \"Hello Simplicity!\" string hardcoded as a large number of ASCII values (being loaded onto the stack, relative to the stack base pointer <code>rbp</code>).</p> <p>There's not a lot of complexity left, at least not at this level. Our ELF is actually quite simple! But wait, there is more!</p>"},{"location":"2024/12/25/a-simple-elf.html#linker-scripts","title":"Linker Scripts","text":"<p>Where do the strange symbols (like <code>__bss_start</code>) come from? And who decides that our <code>startup</code> function should be loaded into memory at <code>0x0040104c</code>? What if we want our code to live in the cool <code>0xc0d30000</code> address range?</p> <p>These things are specified in the linker script. Until now, we have been using the default one, which you can see with <code>ld -verbose</code>. It's very complex. Let's get rid of it.</p> <p>Our simple hello world application doesn't use any global variables. If it had, they would fall into three categories:</p> <ul> <li><code>.rodata</code>: Constants with values provided at compile time, like our hardcoded string.</li> <li><code>.data</code>: Non-const variables with values provided at compile time.</li> <li><code>.bss</code>: Uninitialized global variables.</li> </ul> <p>Let's complicate our program a tiny bit by introducing a symbol for each category. This will provide a more interesting linker script example. Here is the new program <code>hello-data.c</code>:</p> <pre><code>const char message[] = \"Hello Simplicity!\\n\";   // .rodata\nunsigned long length = sizeof(message) - 1;     // .data\nunsigned long status;                           // .bss\n\nint main() {\n  // write(1, message, length)\n  asm volatile(\"mov $1, %%rax\\n\"                // write syscall number (0x01)\n               \"mov $1, %%rdi\\n\"                // Stdout file descriptor (0x01)\n               \"mov %0, %%rsi\\n\"                // Message buffer\n               \"mov %1, %%rdx\\n\"                // Buffer length\n               \"syscall\"                        // Make the syscall\n               :                                // No output operands\n               : \"r\"(message), \"r\"(length)      // Input operands\n               : \"%rax\", \"%rdi\", \"%rsi\", \"%rdx\" // Clobbered registers\n  );\n\n  return 0;\n}\n\nvoid startup() {\n  status = main();\n\n  // exit(status)\n  asm volatile(\"mov $0x3c, %%rax\\n\" // exit syscall number (0x3c)\n               \"mov %0, %%rdi\\n\"    // exit status\n               \"syscall\"            // Make the syscall\n               :                    // No output operands\n               : \"r\"(status)        // Input operands\n               : \"%rax\", \"%rdi\"     // Clobbered registers\n  );\n}\n</code></pre> <p>Looking at the symbol table again, without using a custom linker script, we can see the globals in <code>.data</code>, <code>.rodata</code> and <code>.bss</code> respectively:</p> <pre><code>000000000040102f g     F .text  000000000000002d startup\n0000000000403010 g     O .data  0000000000000008 length\n0000000000402000 g     O .rodata    000000000000000e message\n0000000000401000 g     F .text  000000000000002f main\n0000000000403018 g     O .bss   0000000000000008 status\n</code></pre> <p>Now, let's create a simple and fun linker script (<code>hello.ld</code>) with a cool memory map and emojis in the section names:</p> <pre><code>MEMORY {\n  IRAM (rx) : ORIGIN = 0xC0DE0000, LENGTH = 0x1000\n  RAM  (rw) : ORIGIN = 0xFEED0000, LENGTH = 0x1000\n  ROM  (r)  : ORIGIN = 0xDEAD0000, LENGTH = 0x1000\n}\n\nSECTIONS\n{\n  \"\ud83d\udcdc .text\" : {\n    *(.text*)\n  } &gt; IRAM\n\n  \"\ud83d\udce6 .data\" : {\n    *(.data*)\n  } &gt; RAM\n\n  \"\ud83d\udcc1 .bss\" : {\n    *(.bss*)\n  } &gt; RAM\n\n  \"\ud83e\uddca .rodata\" : {\n    *(.rodata*)\n  }  &gt; ROM\n\n  /DISCARD/ : { *(.comment) }\n}\n\nENTRY(startup)\n</code></pre> <p>We use the same build options as before but add <code>-T hello.ld</code> to start using our linker script.</p> <p>This is the simple program in its final form:</p> <pre><code>$ objdump -t -h hello-data\n\nhello-data:     file format elf64-x86-64\n\nSections:\nIdx Name          Size      VMA               LMA               File off  Algn\n  0 \ud83d\udcdc .text    0000005c  00000000c0de0000  00000000c0de0000  00001000  2**0\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  1 \ud83d\udce6 .data    00000008  00000000feed0000  00000000feed0000  00003000  2**3\n                  CONTENTS, ALLOC, LOAD, DATA\n  2 \ud83d\udcc1 .bss     00000008  00000000feed0008  00000000feed0008  00003008  2**3\n                  ALLOC\n  3 \ud83e\uddca .rodata  00000013  00000000dead0000  00000000dead0000  00002000  2**4\n                  CONTENTS, ALLOC, LOAD, READONLY, DATA\nSYMBOL TABLE:\n0000000000000000 l    df *ABS*  0000000000000000 hello-data.c\n00000000c0de002f g     F \ud83d\udcdc .text    000000000000002d startup\n00000000feed0000 g     O \ud83d\udce6 .data    0000000000000008 length\n00000000dead0000 g     O \ud83e\uddca .rodata  0000000000000013 message\n00000000c0de0000 g     F \ud83d\udcdc .text    000000000000002f main\n00000000feed0008 g     O \ud83d\udcc1 .bss 0000000000000008 status\n</code></pre> <p>Isn't that absolutely adorable?!</p> <p>I've put some sample code over at github.com/4ZM/elf-shenanigans to reproduce the examples in this article.</p> <p>If you want to learn more about linker scripts (and why wouldn't you?!) this is an outstanding technical documentation: \"c_Using_LD\".</p> <p>If you want to explore more ridiculous things to do with section names, check out my other article: \"ELF Shenanigans\".</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Update 2024-12-28: This article made it to the top of Hacker News! There is a lot of interesting comments and links to similar content in the comments.</p> <p>Update 2025-01-12: There are a few issues with the inline assembly in my examples. Here is a better way to write it:</p> <pre><code>// write(1, message, length)\nasm volatile(\"syscall\"        // Make the syscall\n             :                // No output operands\n             : \"a\"(1),        // rax (s#)\n               \"D\"(1),        // rdi (fd)\n               \"S\"(message),  // rsi\n               \"d\"(length)    // rdi\n             : \"rcx\", \"r11\",  // Clobbered registers\n               \"cc\", \"memory\" // Clobbered flags and memory\n    );\n</code></pre> <p>This will make sure the right values are in the right registers, some times without actually having to do anything. It also lists the <code>r11</code> as clobbered. But, there is also another issue in the examples. It's related to stack alignment. If you try compiling with <code>-O2</code> you will likely get a segfault since the stack is not 16 byte aligned. Fixing this would sidetrack and obscure the narrative of the article. Just be warned, this is not how you write production code, this is blogware.</p>"},{"location":"2024/12/25/elf-shenanigans.html","title":"ELF Shenanigans - Holiday Special","text":"<p>Did you know that it's possible to use ANSI color codes and emojis in the section names of yor ELF binaries? I didn't. So, I had to try, and <code>objdump</code> output has never been prettier. \ud83c\udf84</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>As hackers, we some times get a \"what if I just...\" moment. A delightful spark of inspiration and mischief that can not be ignored. I found my self pondering if it would be possible to put ANSI Codes into ELF section names. Could we perhaps replace <code>.text</code> section name with some color and spice in the output of <code>objdump</code>?</p> <p>It turns out, that works like a charm and I have never seen a better looking symbol table!</p> ![console](xmas.gif) <p>The assembler complains about silly section names, but putting control characters in a linker script works just fine.</p> <pre><code>MEMORY {\n  XMAS (rx) : ORIGIN = 0xDEC25000, LENGTH = 0x1000\n}\n\nSECTIONS\n{\n  \"\ud83c\udf84 ^[[31;49m\u2593\u2592\u2591^[[0m ^[[95;1;5m\ud83c\udf1f^[[0m ^[[31m\u2591\u2592\u2593^[[92;41;1mXMAS^[[31;49m\u2593\u2592\u2591^[[0m ^[[95;1;5m\ud83c\udf1f^[[0m ^[[31;49m\u2591\u2592\u2593^[[0m \ud83c\udf84\" : {\n    *(.text*)\n  } &gt; XMAS\n}\n\nENTRY(xmas)\n</code></pre> <p>I've put some sample code over at github.com/4ZM/elf-shenanigans to reproduce the demo.</p> <p>If you can't get enough of linker scripts or if you want to learn more about ELFs, my other article \"A Simple ELF\" might be helpful.</p> <p>What else could we do to the <code>objdump</code> output? Multi-line ASCII art? Playing the terminal bell? Blinking text? Happy exploring, and happy holidays!</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2025/03/31/low-level.html","title":"Low, Lower, Lowest Level Programming","text":"<p>How low can you go? When it comes to embedded programming, the \"full stack\" starts at the PCB. In a recent talk at our local C++ meetup in Stockholm, I explored this in depth. Let's find out what's at the end of the rainbow by diving into topics like memory management, interrupt vector tables and electronics!</p> <pre><p>\u2022  \u2022  \u2022</p></pre>"},{"location":"2025/04/05/bitter-prediction.html","title":"The Bitter Prediction","text":"<p>I'm one of many developers experiencing the whirlwind emotional phases of AI's introduction: dismissal, disbelief, excitement, and acceptance. But after working with Claude, Copilot, and Gemini for a while, I have concerns...</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>I recently spent a few eye-opening evenings with Claude Code, refactoring a small hobby project written in Rust. Each night, I was blown away by the incredible capabilities of the tool. It reasoned about my code in a deep and meaningful way. It discovered the project's architectural patterns and understood my intentions as a programmer. I've never been more productive! Not only that, the generated code was high-quality, efficient, and conformed to my coding guidelines. It routinely \"checked its work\" by running unit tests to eliminate hallucinations and bugs. It was a thing of beauty and it left me increasingly excited about trying it on all the other projects I\u2019m working on.</p> <p>For a few days, I had a fantastic time. Then, I didn\u2019t. It wasn\u2019t that the tool wasn\u2019t performing well, I just missed writing code.</p> <p>I recognized the feeling from a moment in my youth. Back then, I loved playing the game \"UFO: Enemy Unknown.\" The game involved building a global defense network to ward off an alien invasion. Building bases, researching new technologies, and buying weapons were all part of the strategy mechanics. At the same time, I was beginning to explore how software was built. Using a hex editor and a disassembler, I would pick apart things to see how they worked. This was another kind of game that I thoroughly enjoyed. One day, it hit me: the amount of money I had in the game must somehow be stored in the save files! I could use my hex editor to change it.</p> ![xcom](xcom.png){ width=60% } <p>Sure enough, my plan worked. I awarded myself a generous donation, and for a few hours, I was thrilled. I could buy all the cool stuff I couldn\u2019t afford before and I had no problem fending off the pesky alien invasion. Aliens were no match for my hex editor.</p> <p>The next day, I stopped playing the game. It wasn\u2019t fun anymore. It left me unsatisfied. Sure, I would win every time, but I didn\u2019t enjoy it. Not only that, even playing without cheating lost its shine. Why bother playing when I knew there was an easier way to win?</p> <p>This is the exact same feeling I\u2019m left with after a few days of using Claude Code. I don\u2019t enjoy using the tool as much as I enjoy writing code, but if it gets me to the goal faster, no sane employer would allow me to do it any other way. Will programming eventually be relegated to a hobby? Something that you can do in your spare time to amuse yourself, like a crossword puzzle?</p> <p>But even as a hobby, it would leave me unsatisfied, knowing deep down that an AI could do it better. To be clear, I\u2019m not saying we\u2019re there yet. Our AI programming tools are not yet good enough, but I see no reason why they wouldn\u2019t be within a few years\u2014or even months. Let\u2019s just say it\u2019s a bitter prediction on my part.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Fast forward a few weeks, and I started noticing how much money I was spending on these tools. Programming used to be an amortized O(1) cost endeavor: once you had your computer, it was essentially free. If it hadn\u2019t been, I\u2019m sure I wouldn\u2019t have had a chance to get into it as a kid.</p> <p>Working with an AI agent, I sometimes find myself spending $5 a day on code generation and refactoring. This deeply concerns me.</p>"},{"location":"2025/04/05/bitter-prediction.html#forty-six-percent-of-the-global-population-lives-on-less-than-5-per-day","title":"<p>Forty-six percent of the global population lives on less than $5 per day.</p>","text":"<p>In some countries, more than 90% of the population lives on less than $5 per day. If agentic AI code generation becomes the most effective way to write high-quality code, this will create a massive barrier to entry. Access to technology is already a major class and inequality problem. My bitter prediction is that these expensive frontier models will become as indispensable for software development as they are inaccessible to most of the world\u2019s population.</p> <p>Don't even get me started on the green house gas emissions of data centers...</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>At the end of the day, I believe this type of agentic AI development is inevitable, regardless of what I happen to think about it. It makes economic sense, and capitalism is not sentimental. Nor does it care about how much fun we have as long as we produce and consume efficiently.</p> <p>Perhaps I\u2019m getting old? Perhaps I'm a luddite? I definitely hope that I\u2019m wrong... But I predict software development will be a lot less fun in the years to come, and that is a very bitter prediction in deed.</p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Update 2025-05-05: This article really got some discussion going at Hacker News without me even realizing until now! There is a lot of interesting comments and perspectives offered there.</p>"},{"location":"2025/05/19/awesome-apis.html","title":"Building Awesome APIs","text":"<p>I've recently delivered two talks on API design best practices for libraries. First at ACCU 2025 and then again in the Stockholm C++ Meetup. It's a fun topic and even if the presentations start out the same way they soon diverge both in style and contents. </p> <pre><p>\u2022  \u2022  \u2022</p></pre> <p>Here is a recording from the Stockholm C++ Meetup on May 8th. This is a longer version of the talk with a lot of interaction and participation from the audience. </p> <p>The ACCU presentation from Apr 3rd is a more structured 20min conference talk, but it's not yet available online. I'll update the blog when it's up on YouTube. </p>"},{"location":"archive/2025.html","title":"2025","text":""},{"location":"archive/2024.html","title":"2024","text":""},{"location":"category/c.html","title":"C++","text":""},{"location":"category/best-practices.html","title":"Best Practices","text":""},{"location":"category/ai.html","title":"AI","text":""},{"location":"category/philosophy.html","title":"Philosophy","text":""},{"location":"category/embedded.html","title":"Embedded","text":""},{"location":"category/toolchains.html","title":"Toolchains","text":""},{"location":"category/shenanigans.html","title":"Shenanigans","text":""},{"location":"category/git.html","title":"Git","text":""},{"location":"category/beyond-the-basics.html","title":"Beyond the Basics","text":""},{"location":"category/code-review.html","title":"Code Review","text":""},{"location":"category/leadership.html","title":"Leadership","text":""},{"location":"category/python.html","title":"Python","text":""}]}